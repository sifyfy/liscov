//! Signalä¾å­˜é–¢ä¿‚åˆ†æãƒ»æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Phase 4.1)
//!
//! Signalä½¿ç”¨çŠ¶æ³ã®åˆ†æã¨æœ€é©åŒ–ã‚’æä¾›ï¼š
//! - Signalä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã®ä½œæˆ
//! - é‡è¤‡Signalæ¤œå‡ºãƒ»çµ±åˆ
//! - Signalæ›´æ–°é »åº¦ç›£è¦–
//! - æœ€é©åŒ–æ¨å¥¨äº‹é …ç”Ÿæˆ
//! - Phase 4.2: Batchæ›´æ–°æ©Ÿèƒ½

use std::collections::HashMap;
use std::time::Instant;

/// Signalè­˜åˆ¥å­
pub type SignalId = String;

/// Phase 4.2: Batchæ›´æ–°ã‚·ã‚¹ãƒ†ãƒ 
use std::collections::VecDeque;

/// Batchæ›´æ–°ã‚¢ã‚¤ãƒ†ãƒ 
#[derive(Debug, Clone)]
pub struct BatchUpdateItem {
    pub signal_id: SignalId,
    pub timestamp: Instant,
    pub update_type: BatchUpdateType,
}

/// Batchæ›´æ–°ã®ç¨®é¡
#[derive(Debug, Clone, PartialEq)]
pub enum BatchUpdateType {
    /// é€šå¸¸ã®æ›´æ–°
    Normal,
    /// é«˜å„ªå…ˆåº¦æ›´æ–°ï¼ˆUIå¿œç­”æ€§é‡è¦ï¼‰
    HighPriority,
    /// ä½å„ªå…ˆåº¦æ›´æ–°ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ï¼‰
    LowPriority,
    /// DOMæ“ä½œä¼´ã†æ›´æ–°
    DomUpdate,
}

/// Batchæ›´æ–°ç®¡ç†
#[derive(Debug)]
pub struct BatchUpdateManager {
    /// æ›´æ–°ã‚­ãƒ¥ãƒ¼
    queue: VecDeque<BatchUpdateItem>,
    /// å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    processing: bool,
    /// çµ±è¨ˆæƒ…å ±
    stats: BatchStats,
}

/// Batchçµ±è¨ˆæƒ…å ±
#[derive(Debug, Clone)]
pub struct BatchStats {
    pub total_batched: u64,
    pub high_priority_count: u64,
    pub dom_update_count: u64,
    pub average_batch_size: f32,
    pub last_batch_time: Option<Instant>,
}

impl BatchUpdateManager {
    /// æ–°ã—ã„Batchæ›´æ–°ç®¡ç†ã‚’ä½œæˆ
    pub fn new() -> Self {
        Self {
            queue: VecDeque::new(),
            processing: false,
            stats: BatchStats {
                total_batched: 0,
                high_priority_count: 0,
                dom_update_count: 0,
                average_batch_size: 0.0,
                last_batch_time: None,
            },
        }
    }

    /// æ›´æ–°ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    pub fn queue_update(&mut self, signal_id: SignalId, update_type: BatchUpdateType) {
        let item = BatchUpdateItem {
            signal_id: signal_id.clone(),
            timestamp: Instant::now(),
            update_type: update_type.clone(),
        };

        // å„ªå…ˆåº¦ã«åŸºã¥ã„ã¦ã‚­ãƒ¥ãƒ¼ã«æŒ¿å…¥
        match item.update_type {
            BatchUpdateType::HighPriority => {
                self.queue.push_front(item);
                self.stats.high_priority_count += 1;
            }
            BatchUpdateType::DomUpdate => {
                // DOMæ›´æ–°ã¯ç‰¹åˆ¥ãªå‡¦ç†é †åº
                let insert_pos = self
                    .queue
                    .iter()
                    .position(|existing| {
                        !matches!(existing.update_type, BatchUpdateType::HighPriority)
                    })
                    .unwrap_or(self.queue.len());
                self.queue.insert(insert_pos, item);
                self.stats.dom_update_count += 1;
            }
            _ => {
                self.queue.push_back(item);
            }
        }

        self.stats.total_batched += 1;

        let queue_len = self.queue.len();

        tracing::debug!(
            "ğŸ“¦ [BATCH] Queued {:?} update for {} (queue size: {})",
            update_type,
            signal_id,
            queue_len
        );
    }

    /// Batchå‡¦ç†ã‚’å®Ÿè¡Œ - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿è­·ä»˜ã
    pub async fn process_batch(&mut self) -> Result<usize, String> {
        if self.processing || self.queue.is_empty() {
            return Ok(0);
        }

        self.processing = true;
        let batch_start = Instant::now();
        let batch_size = self.queue.len();

        tracing::info!("ğŸš€ [BATCH] Processing batch of {} updates", batch_size);

        // 100msã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿è­·
        let processed = match tokio::time::timeout(
            tokio::time::Duration::from_millis(100),
            self.process_with_animation_frame(),
        )
        .await
        {
            Ok(result) => result?,
            Err(_) => {
                tracing::warn!(
                    "âš ï¸ [BATCH] Processing timeout (>100ms), processed some items and stopping. Queue size: {}",
                    self.queue.len()
                );
                // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯æ®‹ã‚Šã®ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯é˜²æ­¢
                let remaining = self.queue.len();
                self.queue.clear();
                batch_size - remaining
            }
        };

        // çµ±è¨ˆæ›´æ–°
        self.stats.average_batch_size = (self.stats.average_batch_size + batch_size as f32) / 2.0;
        self.stats.last_batch_time = Some(batch_start);

        self.processing = false;

        tracing::info!(
            "âœ… [BATCH] Processed {} updates in {:.2}ms",
            processed,
            batch_start.elapsed().as_secs_f32() * 1000.0
        );

        Ok(processed)
    }

    /// requestAnimationFrameãƒ™ãƒ¼ã‚¹ã®å‡¦ç†
    async fn process_with_animation_frame(&mut self) -> Result<usize, String> {
        let mut processed = 0;
        let batch_size = self.queue.len();

        while !self.queue.is_empty() {
            // ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§processing
            let frame_items = self.collect_frame_items();

            if frame_items.is_empty() {
                break;
            }

            // ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®å®Ÿè¡Œ
            self.execute_frame_updates(&frame_items).await?;
            processed += frame_items.len();

            // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§å¾…æ©Ÿ
            if processed < batch_size {
                self.wait_for_next_frame().await;
            }
        }

        Ok(processed)
    }

    /// ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®ã‚¢ã‚¤ãƒ†ãƒ åé›†
    fn collect_frame_items(&mut self) -> Vec<BatchUpdateItem> {
        let max_per_frame = 5; // ãƒ•ãƒ¬ãƒ¼ãƒ è¾ºã‚Šã®æœ€å¤§å‡¦ç†æ•°
        let mut frame_items = Vec::new();

        for _ in 0..max_per_frame.min(self.queue.len()) {
            if let Some(item) = self.queue.pop_front() {
                frame_items.push(item);
            }
        }

        frame_items
    }

    /// ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–°ã®å®Ÿè¡Œ
    async fn execute_frame_updates(&self, items: &[BatchUpdateItem]) -> Result<(), String> {
        // DOMæ›´æ–°ã¨Signalæ›´æ–°ã‚’åˆ†é›¢
        let mut dom_updates = Vec::new();
        let mut signal_updates = Vec::new();

        for item in items {
            match item.update_type {
                BatchUpdateType::DomUpdate => dom_updates.push(item),
                _ => signal_updates.push(item),
            }
        }

        // DOMæ›´æ–°ã‚’å…ˆã«å®Ÿè¡Œ
        if !dom_updates.is_empty() {
            self.execute_dom_updates(&dom_updates).await?;
        }

        // Signalæ›´æ–°ã‚’å¾Œã«å®Ÿè¡Œ
        if !signal_updates.is_empty() {
            self.execute_signal_updates(&signal_updates).await?;
        }

        Ok(())
    }

    /// DOMæ›´æ–°ã®å®Ÿè¡Œ
    async fn execute_dom_updates(&self, items: &[&BatchUpdateItem]) -> Result<(), String> {
        tracing::debug!("ğŸ¨ [BATCH] Executing {} DOM updates", items.len());

        for item in items {
            // DOMæ“ä½œã®batchå‡¦ç†
            match item.signal_id.as_str() {
                "chat_scroll" => {
                    // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†ã®batchåŒ–
                    let _ = dioxus::document::eval(
                        r#"
                        if (!window.liscovBatchScrollPending) {
                            window.liscovBatchScrollPending = true;
                            requestAnimationFrame(() => {
                                const container = document.getElementById('liscov-message-list');
                                if (container) {
                                    container.scrollTop = container.scrollHeight;
                                }
                                window.liscovBatchScrollPending = false;
                            });
                        }
                    "#,
                    )
                    .await;
                }
                "highlight_update" => {
                    // ãƒã‚¤ãƒ©ã‚¤ãƒˆå‡¦ç†ã®batchåŒ– - å¼·åŒ–ç‰ˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                    let _ = dioxus::document::eval(r#"
                        if (!window.liscovBatchHighlightPending) {
                            window.liscovBatchHighlightPending = true;
                            
                            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿è­·ï¼ˆ100msä»¥å†…ã«å®Œäº†ï¼‰
                            const timeout = setTimeout(() => {
                                console.warn('ğŸš¨ [BATCH] Highlight update timeout, resetting flag');
                                window.liscovBatchHighlightPending = false;
                            }, 100);
                            
                            requestAnimationFrame(() => {
                                try {
                                    // ãƒã‚¤ãƒ©ã‚¤ãƒˆå‡¦ç†ã‚’batchå®Ÿè¡Œ
                                    const highlighted = document.querySelectorAll('.liscov-highlight-animation');
                                    if (highlighted.length > 0) {
                                        highlighted.forEach(el => {
                                            el.style.animation = 'highlight-pulse 2s ease-in-out';
                                        });
                                    }
                                } catch (error) {
                                    console.error('ğŸš¨ [BATCH] Highlight update error:', error);
                                } finally {
                                    clearTimeout(timeout);
                                    window.liscovBatchHighlightPending = false;
                                }
                            });
                        }
                    "#).await;
                }
                _ => {}
            }
        }

        Ok(())
    }

    /// Signalæ›´æ–°ã®å®Ÿè¡Œ
    async fn execute_signal_updates(&self, items: &[&BatchUpdateItem]) -> Result<(), String> {
        tracing::debug!("ğŸ“Š [BATCH] Executing {} Signal updates", items.len());

        // Signalæ›´æ–°ã¯ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’å‘ä¸Š
        let mut signal_groups: HashMap<String, Vec<&BatchUpdateItem>> = HashMap::new();

        for item in items {
            signal_groups
                .entry(item.signal_id.clone())
                .or_insert_with(Vec::new)
                .push(item);
        }

        // ã‚°ãƒ«ãƒ¼ãƒ—æ¯ã«å‡¦ç†
        for (signal_id, group_items) in signal_groups {
            tracing::debug!(
                "ğŸ”§ [BATCH] Processing {} updates for signal: {}",
                group_items.len(),
                signal_id
            );

            // æœ€æ–°ã®æ›´æ–°ã®ã¿é©ç”¨ï¼ˆé‡è¤‡å‰Šé™¤ï¼‰
            if let Some(latest_item) = group_items.last() {
                // å®Ÿéš›ã®Signalæ›´æ–°å‡¦ç†ã¯å‘¼ã³å‡ºã—å´ã§å®Ÿè£…
                tracing::debug!("âœ… [BATCH] Applied update for: {}", latest_item.signal_id);
            }
        }

        Ok(())
    }

    /// æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§å¾…æ©Ÿ
    async fn wait_for_next_frame(&self) {
        // 16ms â‰ˆ 60fps
        tokio::time::sleep(tokio::time::Duration::from_millis(16)).await;
    }

    /// ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’å–å¾—
    pub fn queue_size(&self) -> usize {
        self.queue.len()
    }

    /// çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    pub fn get_stats(&self) -> &BatchStats {
        &self.stats
    }
}

impl Default for BatchUpdateManager {
    fn default() -> Self {
        Self::new()
    }
}

/// ã‚°ãƒ­ãƒ¼ãƒãƒ«Batchæ›´æ–°ç®¡ç†
static GLOBAL_BATCH_MANAGER: OnceLock<Arc<Mutex<BatchUpdateManager>>> = OnceLock::new();

/// ã‚°ãƒ­ãƒ¼ãƒãƒ«Batchç®¡ç†ã‚’å–å¾—
pub fn get_batch_manager() -> Arc<Mutex<BatchUpdateManager>> {
    GLOBAL_BATCH_MANAGER
        .get_or_init(|| {
            tracing::info!("ğŸ“¦ [BATCH] Creating global batch update manager");
            Arc::new(Mutex::new(BatchUpdateManager::new()))
        })
        .clone()
}

/// Phase 4.2: Batchæ›´æ–°ä¾¿åˆ©é–¢æ•°
pub fn queue_batch_update(signal_id: &str, update_type: BatchUpdateType) {
    if let Ok(mut manager) = get_batch_manager().lock() {
        manager.queue_update(signal_id.to_string(), update_type);
    }
}

/// Phase 4.2: Batchå‡¦ç†å®Ÿè¡Œä¾¿åˆ©é–¢æ•°
pub async fn process_batch_updates() -> usize {
    if let Ok(mut manager) = get_batch_manager().lock() {
        manager.process_batch().await.unwrap_or(0)
    } else {
        0
    }
}

/// Phase 4.2: Batchçµ±è¨ˆå–å¾—ä¾¿åˆ©é–¢æ•°
pub fn get_batch_stats() -> Option<BatchStats> {
    if let Ok(manager) = get_batch_manager().lock() {
        Some(manager.get_stats().clone())
    } else {
        None
    }
}

/// Signalã®ç¨®é¡
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum SignalType {
    // ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºé–¢é€£
    ChatMessage,
    FilteredMessage,
    MessageFilter,

    // UIçŠ¶æ…‹
    AutoScrollEnabled,
    UserHasScrolled,
    ShowFilterPanel,
    ShowTimestamps,
    MessageFontSize,

    // ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    HighlightEnabled,
    HighlightDuration,
    HighlightedMessageIds,

    // å†…éƒ¨åˆ¶å¾¡
    LastMessageCount,
    ScrollPosition,

    // ã‚«ã‚¹ã‚¿ãƒ 
    Custom(String),
}

/// Signalæƒ…å ±
#[derive(Debug, Clone)]
pub struct SignalInfo {
    pub id: SignalId,
    pub signal_type: SignalType,
    pub component: String,
    pub created_at: Instant,
    pub update_count: u64,
    pub last_updated: Option<Instant>,
}

/// Signalæœ€é©åŒ–ã®æ¨å¥¨äº‹é …
#[derive(Debug, Clone)]
pub struct OptimizationRecommendation {
    pub recommendation_type: OptimizationType,
    pub signal_ids: Vec<SignalId>,
    pub expected_improvement: f32,
    pub description: String,
    pub priority: u8, // 1ãŒæœ€é«˜å„ªå…ˆåº¦
}

/// æœ€é©åŒ–ã®ç¨®é¡
#[derive(Debug, Clone, PartialEq)]
pub enum OptimizationType {
    /// é‡è¤‡Signalçµ±åˆ
    MergeDuplicate,
    /// Signalå‰Šé™¤
    RemoveUnused,
    /// Batchæ›´æ–°
    BatchUpdate,
    /// ä¾å­˜é–¢ä¿‚ç°¡ç´ åŒ–
    SimplifyDependency,
}

/// Signalä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•
#[derive(Debug)]
pub struct SignalDependencyGraph {
    /// Signalæƒ…å ±
    signals: HashMap<SignalId, SignalInfo>,
    /// çµ±è¨ˆæƒ…å ±
    stats: GraphStats,
}

/// ã‚°ãƒ©ãƒ•çµ±è¨ˆæƒ…å ±
#[derive(Debug, Clone)]
pub struct GraphStats {
    pub total_signals: usize,
    pub duplicate_signals: usize,
    pub unused_signals: usize,
    pub memory_usage: usize,
    pub last_analyzed: Instant,
}

impl SignalDependencyGraph {
    /// æ–°ã—ã„ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    pub fn new() -> Self {
        Self {
            signals: HashMap::new(),
            stats: GraphStats {
                total_signals: 0,
                duplicate_signals: 0,
                unused_signals: 0,
                memory_usage: 0,
                last_analyzed: Instant::now(),
            },
        }
    }

    /// Signalã‚’ç™»éŒ²
    pub fn register_signal(&mut self, id: SignalId, signal_type: SignalType, component: String) {
        let signal_info = SignalInfo {
            id: id.clone(),
            signal_type,
            component,
            created_at: Instant::now(),
            update_count: 0,
            last_updated: None,
        };

        self.signals.insert(id, signal_info);
        self.stats.total_signals = self.signals.len();

        tracing::debug!(
            "ğŸ“Š [SIGNAL] Registered: {} signals total",
            self.stats.total_signals
        );
    }

    /// Signalæ›´æ–°ã‚’è¨˜éŒ²
    pub fn record_update(&mut self, signal_id: &str) {
        if let Some(signal) = self.signals.get_mut(signal_id) {
            signal.update_count += 1;
            signal.last_updated = Some(Instant::now());
        }
    }

    /// é‡è¤‡Signalæ¤œå‡º
    pub fn detect_duplicate_signals(&self) -> Vec<Vec<SignalId>> {
        let mut duplicates = Vec::new();
        let mut type_groups: HashMap<SignalType, Vec<SignalId>> = HashMap::new();

        // å‹åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        for (id, info) in &self.signals {
            type_groups
                .entry(info.signal_type.clone())
                .or_insert_with(Vec::new)
                .push(id.clone());
        }

        // åŒã˜å‹ã§è¤‡æ•°ã®SignalãŒã‚ã‚‹å ´åˆã¯é‡è¤‡å€™è£œ
        for (_signal_type, ids) in type_groups {
            if ids.len() > 1 {
                duplicates.push(ids);
            }
        }

        duplicates
    }

    /// æœªä½¿ç”¨Signalæ¤œå‡º
    pub fn detect_unused_signals(&self) -> Vec<SignalId> {
        self.signals
            .iter()
            .filter(|(_, info)| info.update_count == 0)
            .map(|(id, _)| id.clone())
            .collect()
    }

    /// æœ€é©åŒ–æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    pub fn generate_optimization_recommendations(&mut self) -> Vec<OptimizationRecommendation> {
        let mut recommendations = Vec::new();

        // 1. é‡è¤‡Signalçµ±åˆ
        let duplicates = self.detect_duplicate_signals();
        for duplicate_group in duplicates.iter() {
            if duplicate_group.len() > 1 {
                recommendations.push(OptimizationRecommendation {
                    recommendation_type: OptimizationType::MergeDuplicate,
                    signal_ids: duplicate_group.clone(),
                    expected_improvement: (duplicate_group.len() - 1) as f32 * 0.2,
                    description: format!(
                        "Merge {} duplicate signals of same type",
                        duplicate_group.len()
                    ),
                    priority: 1,
                });
            }
        }

        // 2. æœªä½¿ç”¨Signalå‰Šé™¤
        let unused = self.detect_unused_signals();
        if !unused.is_empty() {
            recommendations.push(OptimizationRecommendation {
                recommendation_type: OptimizationType::RemoveUnused,
                signal_ids: unused.clone(),
                expected_improvement: unused.len() as f32 * 0.1,
                description: format!("Remove {} unused signals", unused.len()),
                priority: 2,
            });
        }

        // å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        recommendations.sort_by_key(|r| r.priority);
        recommendations
    }

    /// çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
    pub fn update_stats(&mut self) {
        self.stats.total_signals = self.signals.len();
        self.stats.duplicate_signals = self
            .detect_duplicate_signals()
            .iter()
            .map(|g| g.len() - 1)
            .sum();
        self.stats.unused_signals = self.detect_unused_signals().len();
        self.stats.last_analyzed = Instant::now();
    }

    /// çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    pub fn get_stats(&self) -> &GraphStats {
        &self.stats
    }

    /// åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    pub fn generate_analysis_report(&mut self) -> String {
        self.update_stats();

        let mut report = String::new();
        report.push_str("=== Signal Optimization Analysis Report ===\n\n");

        // åŸºæœ¬çµ±è¨ˆ
        report.push_str(&format!("ğŸ“Š Total Signals: {}\n", self.stats.total_signals));
        report.push_str(&format!(
            "ğŸ”„ Duplicate Signals: {}\n",
            self.stats.duplicate_signals
        ));
        report.push_str(&format!(
            "ğŸ—‘ï¸ Unused Signals: {}\n",
            self.stats.unused_signals
        ));
        report.push_str(&format!(
            "ğŸ’¾ Memory Usage: {} bytes\n\n",
            self.stats.memory_usage
        ));

        // Componentåˆ¥çµ±è¨ˆ
        let mut component_stats: HashMap<String, usize> = HashMap::new();
        for signal in self.signals.values() {
            *component_stats.entry(signal.component.clone()).or_insert(0) += 1;
        }

        report.push_str("ğŸ“¦ Signals by Component:\n");
        for (component, count) in &component_stats {
            report.push_str(&format!("  {} -> {} signals\n", component, count));
        }
        report.push_str("\n");

        // é‡è¤‡Signalè©³ç´°
        let duplicates = self.detect_duplicate_signals();
        if !duplicates.is_empty() {
            report.push_str("ğŸ” Duplicate Signal Groups:\n");
            for (i, duplicate_group) in duplicates.iter().enumerate() {
                let signal_type = self
                    .signals
                    .get(&duplicate_group[0])
                    .map(|s| format!("{:?}", s.signal_type))
                    .unwrap_or_else(|| "Unknown".to_string());
                report.push_str(&format!(
                    "  Group {}: {} ({} signals)\n",
                    i + 1,
                    signal_type,
                    duplicate_group.len()
                ));
                for signal_id in duplicate_group {
                    if let Some(signal) = self.signals.get(signal_id) {
                        report.push_str(&format!("    - {} ({})\n", signal_id, signal.component));
                    }
                }
            }
            report.push_str("\n");
        }

        // æœ€é©åŒ–æ¨å¥¨äº‹é …
        let recommendations = self.generate_optimization_recommendations();
        if !recommendations.is_empty() {
            report.push_str("ğŸ’¡ Optimization Recommendations:\n");
            for (i, rec) in recommendations.iter().enumerate() {
                report.push_str(&format!(
                    "  {}. [Priority {}] {}\n",
                    i + 1,
                    rec.priority,
                    rec.description
                ));
                report.push_str(&format!(
                    "     Expected improvement: {:.1}%\n",
                    rec.expected_improvement * 100.0
                ));
                report.push_str(&format!(
                    "     Affected signals: {}\n",
                    rec.signal_ids.len()
                ));
            }
        } else {
            report.push_str("âœ… No optimization recommendations at this time.\n");
        }

        report
    }

    /// ç¾åœ¨ã®Signalä¸€è¦§ã‚’å–å¾—
    pub fn list_signals(&self) -> Vec<&SignalInfo> {
        self.signals.values().collect()
    }
}

impl Default for SignalDependencyGraph {
    fn default() -> Self {
        Self::new()
    }
}

/// ã‚°ãƒ­ãƒ¼ãƒãƒ«Signalä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•
use std::sync::{Arc, Mutex, OnceLock};

static GLOBAL_SIGNAL_GRAPH: OnceLock<Arc<Mutex<SignalDependencyGraph>>> = OnceLock::new();

/// ã‚°ãƒ­ãƒ¼ãƒãƒ«Signalã‚°ãƒ©ãƒ•ã‚’å–å¾—
pub fn get_signal_graph() -> Arc<Mutex<SignalDependencyGraph>> {
    GLOBAL_SIGNAL_GRAPH
        .get_or_init(|| {
            tracing::info!("ğŸ“Š [SIGNAL] Creating global signal dependency graph");
            Arc::new(Mutex::new(SignalDependencyGraph::new()))
        })
        .clone()
}

/// Signalç™»éŒ²ä¾¿åˆ©é–¢æ•°
pub fn register_signal(id: &str, signal_type: SignalType, component: &str) {
    if let Ok(mut graph) = get_signal_graph().lock() {
        graph.register_signal(id.to_string(), signal_type, component.to_string());
    }
}

/// Signalæ›´æ–°è¨˜éŒ²ä¾¿åˆ©é–¢æ•°
pub fn record_signal_update(signal_id: &str) {
    if let Ok(mut graph) = get_signal_graph().lock() {
        graph.record_update(signal_id);
    }
}

/// åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¾¿åˆ©é–¢æ•°
pub fn generate_signal_analysis_report() -> String {
    if let Ok(mut graph) = get_signal_graph().lock() {
        graph.generate_analysis_report()
    } else {
        "Error: Could not access signal graph".to_string()
    }
}

/// æœ€é©åŒ–æ¨å¥¨äº‹é …å–å¾—ä¾¿åˆ©é–¢æ•°
pub fn get_optimization_recommendations() -> Vec<OptimizationRecommendation> {
    if let Ok(mut graph) = get_signal_graph().lock() {
        graph.generate_optimization_recommendations()
    } else {
        Vec::new()
    }
}
